{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To crea opencv python environment:\n",
    "```\n",
    "conda create --name py35-opencv3 python=3.5\n",
    "activate py35-opencv3\n",
    "conda install numpy\n",
    "conda install anaconda-client\n",
    "conda install --channel https://conda.anaconda.org/menpo opencv3\n",
    "conda install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = 'D:/ProblemaCamTacticaLugo/3245-scoutingvideo-1.mp4'\n",
    "calib_file = 'D:/ProblemaCamTacticaLugo/calib.csv'\n",
    "\n",
    "# sport field\n",
    "\"\"\"\n",
    "f_tl = [-50.0, 32.0] \n",
    "f_tr = [50.0, 32.0]\n",
    "f_bl = [-50.0, -32.0] \n",
    "f_br = [50.0, -32.0]\n",
    "\"\"\"\n",
    "f_tl = [-25.0, 15.0] \n",
    "f_tr = [25.0, 15.0]\n",
    "f_bl = [-25.0, -15.0] \n",
    "f_br = [25.0, -15.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_pitch_to_image(P):\n",
    "    \"\"\"\n",
    "    Returns the homografy to transform points from the pitch (world Z=0) to texture image\n",
    "    :param matrixP: Full matrix P\n",
    "    :return: homography_pitch_to_texture matrix\n",
    "    \"\"\"\n",
    "    # delete the 3th column, the z component\n",
    "    return np.delete(P, 2, axis=1)\n",
    "\n",
    "def pitch_to_image(pitch, H):\n",
    "    \"\"\"\n",
    "    Project a point from pitch plane to texture plane\n",
    "    :param pitch: pitch point (x, y)\n",
    "    :param H: projection matrix P\n",
    "    :return: texture point (i, j)\n",
    "    \"\"\"\n",
    "    pitch_h = np.append(pitch, 1.0)\n",
    "    transformed = H.dot(pitch_h)\n",
    "    return np.array([transformed[0]/transformed[2], transformed[1]/transformed[2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture(video_file)\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "# open atv calibration csv file\n",
    "calib = pd.read_csv(calib_file)\n",
    "\n",
    "counter = 0\n",
    "for index, row in calib.iterrows():   \n",
    "    # get video frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # skip frames\n",
    "    counter += 1\n",
    "    if counter < 25*200:\n",
    "        continue\n",
    "\n",
    "    if not ret:\n",
    "        print('No more video frames')\n",
    "        break\n",
    "        \n",
    "    # get matrix P\n",
    "    P = np.reshape(row.as_matrix(), (3, 4))\n",
    "    # get Homography to project pitch points to video image\n",
    "    H = homography_pitch_to_image(P)\n",
    "    \n",
    "    # project point to image\n",
    "    p_center = [0.0, 0.0]\n",
    "    p_center_img = pitch_to_image(p_center, H).astype(int)\n",
    "    cv2.circle(frame, tuple(p_center_img), 3, (0, 0, 255), -1)\n",
    "    \n",
    "    f_tl_img = tuple(pitch_to_image(f_tl, H).astype(int))\n",
    "    f_tr_img = tuple(pitch_to_image(f_tr, H).astype(int))\n",
    "    f_bl_img = tuple(pitch_to_image(f_bl, H).astype(int))\n",
    "    f_br_img = tuple(pitch_to_image(f_br, H).astype(int))\n",
    "    \n",
    "    pts = np.array([f_bl_img, f_br_img, f_tr_img, f_tl_img, f_bl_img], np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.polylines(frame, [pts], False, (0, 255, 0))\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
