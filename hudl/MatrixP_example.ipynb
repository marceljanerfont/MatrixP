{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform points from pitch to texture and vice-versa\n",
    "### Matrix P - Projection\n",
    "The P matrix is a 3x4 matrix that given a 3D point in the world reference frame, it is projected into the 2D image in **texture coordinate** reference frame, i.e:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{pt_{world}} = (x, y, z, 1) \\\\\n",
    "\\mathbf{pt_{pitch}} = (a, b, c) = \\mathbf{P_{texture}} * \\mathbf{pt_{world}} \\\\\n",
    "\\mathbf{pt_{texture}} = (i, j) = (a/c, b/c)\n",
    "\\end{align}\n",
    "\n",
    "**Texture coordinate range** is [0.0, 1.0]\n",
    "\n",
    "<img src=\"pitch.png\" style=\"width: 400px;\">\n",
    "\n",
    "### Matrix H - Homography\n",
    "The H matrix is a 3x3 Matrix that transforms points from one plane to another. In our case from pitch to texture and from texture to pitch which is the inverse of the first (pitch to texture homography). **Pitch is the world plane where z=0.** Hence, get matrix **H*pith2texture*** is as simple as discard 3th matrix P column:\n",
    "\n",
    "\n",
    "<img src=\"homo.png\" style=\"width: 500px;\">\n",
    "\n",
    "### How to convert from pitch (world) to texture coordinate system\n",
    "\\begin{align}\n",
    "\\mathbf{pt_{texture}} = \\mathbf{H_{pitch2texture}} * \\mathbf{pt_{pitch}}\n",
    "\\end{align}\n",
    "\n",
    "### How to convert from texture to pitch (world) coordinate system\n",
    "\\begin{align}\n",
    "\\mathbf{pt_{pitch}} = \\mathbf{H_{texture2pitch}} * \\mathbf{pt_{texture}}\n",
    "\\end{align}\n",
    "\n",
    "Where,\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{H_{texture2pitch}} = \\mathbf{H_{pitch2texture}^{-1}}\n",
    "\\end{align}\n",
    "\n",
    "### How to convert from texture to video image coordinate system\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{P_{image}} = \\begin{vmatrix}\n",
    "Width & 0 & 0 \\\\ 0 & Height & 0 \\\\ 0 & 0 & 1\n",
    "\\end{vmatrix} * \\mathbf{P_{texture}}\n",
    "\\end{equation*}\n",
    "\n",
    "Where **`Width`** and **`Height`** refer to the video frame size. \n",
    "\n",
    "### How to transform points from an image A to an image B\n",
    "\n",
    "<img src=\"imageA2imageB.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import what we need\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rodrigues(r):\n",
    "    '''\n",
    "    Rodrigues formula\n",
    "    :param r: 1x3 array of rotations about x, y, and z\n",
    "    :return: the 3x3 rotation matrix\n",
    "    '''\n",
    "    def S(n):\n",
    "        Sn = np.array([\n",
    "            [0.0, -n[2], n[1]],\n",
    "            [n[2], 0.0, -n[0]],\n",
    "            [-n[1], n[0], 0]])\n",
    "        return Sn\n",
    "    theta = np.linalg.norm(r)\n",
    "    if theta > 1e-30:\n",
    "        n = r/theta\n",
    "        Sn = S(n)\n",
    "        R = np.eye(3) + np.sin(theta) * Sn + (1.0 - np.cos(theta)) * np.dot(Sn, Sn)\n",
    "    else:\n",
    "        Sr = S(r)\n",
    "        theta2 = theta ** 2.0\n",
    "        R = np.eye(3) + (1.0 - theta2 / 6.0)*Sr + (0.5 - theta2 / 24.0) * np.dot(Sr, Sr)\n",
    "    return np.mat(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def world_to_texture(pw, P):\n",
    "    \"\"\"\n",
    "    Projects a world point to texture projection plane\n",
    "    :param pw: world point (x, y, z)\n",
    "    :param P: projection matrix P\n",
    "    :return: texture point (i, j)\n",
    "    \"\"\"\n",
    "    pw_h = np.append(pw, 1.0)\n",
    "    pp = P.dot(pw_h)\n",
    "    return np.array([pp[0]/pp[2], pp[1]/pp[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homography_pitch_to_texture(P):\n",
    "    \"\"\"\n",
    "    Returns the homografy to transform points from the pitch (world Z=0) to texture image\n",
    "    :param matrixP: Full matrix P\n",
    "    :return: homography_pitch_to_texture matrix\n",
    "    \"\"\"\n",
    "    # delete the 3th column, the z component\n",
    "    return np.delete(P, 2, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pitch_to_texture(pitch, P):\n",
    "    \"\"\"\n",
    "    Project a point from pitch plane to texture plane\n",
    "    :param pitch: pitch point (x, y)\n",
    "    :param P: projection matrix P\n",
    "    :return: texture point (i, j)\n",
    "    \"\"\"\n",
    "    pitch_h = np.append(pitch, 1.0)\n",
    "    H = homography_pitch_to_texture(P)\n",
    "    transformed = H.dot(pitch_h)\n",
    "    #print(projected)\n",
    "    return np.array([transformed[0]/transformed[2], transformed[1]/transformed[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texture_to_pitch(texture, P):\n",
    "    \"\"\"\n",
    "    Project a point from texture plane to pitch plane\n",
    "    :param texture: texture point (i, j)\n",
    "    :param P: projection matrix P\n",
    "    :return: pitch point (x, y)\n",
    "    \"\"\"\n",
    "    texture_h = np.append(texture, 1.0)\n",
    "    H = homography_pitch_to_texture(P)\n",
    "    Hinv = np.linalg.inv(H)\n",
    "    transformed = Hinv.dot(texture_h)\n",
    "    return np.array([transformed[0]/transformed[2], transformed[1]/transformed[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texture_to_image(texture, width, height):\n",
    "    \"\"\"\n",
    "    Converts a texture coordinate to image coordinate system\n",
    "    \"\"\"\n",
    "    return  np.array([int(float(width)*texture[0]), int(float(height)*texture[1])])\n",
    "\n",
    "def image_to_texture(image, width, height):\n",
    "    \"\"\"\n",
    "    Converts a image coordinate to texture coordinate system\n",
    "    \"\"\"\n",
    "    return  np.array([float(image[0])/float(width), float(image[1])/float(height)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection matrix P from an individual camera\n",
    "The funciton `camera_full_projection_matrix` is only valid for individual cameras. \n",
    "\n",
    "## How to get camera parameters: *aspect_ratio, zoom, skew, pan, tilt, roll, Tx, Ty, Tz* \n",
    "You can find camera parameters **`aspect_ratio, zoom, skew, pan, tilt, roll, Tx, Ty, Tz`** in `C:\\AutomaticTV\\data\\cameras\\{id}.xml`. In XML `<modelcalibration>` tag, for instance:\n",
    "\n",
    "```\n",
    "<modelsCalibration>\n",
    "    <modelCalibration computed=\"true\" sportFieldName=\"Football11\">\n",
    "      <Zoom>1.2124214</Zoom>\n",
    "      <AspectRatio>1.7777778</AspectRatio>\n",
    "      <Skew>0</Skew>\n",
    "      <Pan>-28.826538</Pan>\n",
    "      <Tilt>110.37401</Tilt>\n",
    "      <Roll>-10.530287</Roll>\n",
    "      <Tx>34.07756</Tx>\n",
    "      <Ty>-3.4855517</Ty>\n",
    "      <Tz>74.498503</Tz>\n",
    "    </modelCalibration>\n",
    "  </modelsCalibration>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_full_projection_matrix(aspect_ratio, zoom, skew, pan, tilt, roll, Tx, Ty, Tz):\n",
    "    \"\"\"\n",
    "    Creates projection matrix P from camera model parameters\n",
    "    :param aspect_ratio: camera aspect ratio = image width / image height\n",
    "    :param zoom: camera focal\n",
    "    :param skew:\n",
    "    :param pan:\n",
    "    :param tilt:\n",
    "    :param roll:\n",
    "    :param Tx:\n",
    "    :param Ty:\n",
    "    :param Tz:\n",
    "    :return: the projection Matrix P\n",
    "    \"\"\"\n",
    "    K = np.array([[zoom, skew, 0.5], [0.0, zoom * aspect_ratio, 0.5], [0.0, 0.0, 1.0]])\n",
    "\n",
    "    # Rotation matrix\n",
    "    Rpan = rodrigues(np.array([0.0, 0.0, pan*math.pi/180.0]))\n",
    "    Rtilt = rodrigues(np.array([tilt*math.pi/180.0, 0.0, 0.0]))\n",
    "    Rroll = rodrigues(np.array([0.0, 0.0, roll*math.pi/180.0]))\n",
    "    Mrot = Rroll * Rtilt * Rpan\n",
    "\n",
    "    # Translation vector\n",
    "    t = np.array([Tx, Ty, Tz])\n",
    "    KR = K * Mrot\n",
    "    Kt = np.dot(K, t)\n",
    "\n",
    "    # Projection Martix P\n",
    "    P = np.zeros((3, 4))\n",
    "    P[:, 0] = KR[:, 0].T\n",
    "    P[:, 1] = KR[:, 1].T\n",
    "    P[:, 2] = KR[:, 2].T\n",
    "    P[:, 3] = Kt\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual camera matrix P Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.16255096e+00   4.60527814e-01  -1.76724528e-01   3.47393876e+01]\n",
      " [  2.85291856e-02  -3.33068495e-01  -2.09490260e+00   3.50290524e+01]\n",
      " [  5.97472614e-03   9.22770183e-01  -3.85304415e-01   6.87339230e+01]]\n",
      "world: [-10.   3.   0.]\n",
      "texture: [ 0.34286967  0.47233176]\n",
      "\n",
      "pitch: [-10.   3.]\n",
      "texture: [ 0.34286967  0.47233176]\n",
      "\n",
      "texture: [ 0.34286967  0.47233176]\n",
      "pitch: [-10.  3.]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "# ML\n",
    "camera_model = {\n",
    "    \"aspect_ratio\": 1.7777778,\n",
    "    \"zoom\": 1.1596733,\n",
    "    \"skew\": 0.0,\n",
    "    \"pan\": 0.3709719,\n",
    "    \"tilt\": 112.66264,\n",
    "    \"roll\": 0.85281113,\n",
    "    \"Tx\": 0.32114744,\n",
    "    \"Ty\": 0.32114744,\n",
    "    \"Tz\": 68.733923}\n",
    "P = camera_full_projection_matrix(**camera_model)\n",
    "\n",
    "print(P)\n",
    "# project world point\n",
    "x = -10.0\n",
    "y = 3.0\n",
    "world = np.array([x, y, 0.0])\n",
    "print(\"world: {}\".format(world))\n",
    "texture = world_to_texture(world, P)\n",
    "print(\"texture: {}\".format(texture))\n",
    "\"\"\"\n",
    "if (texture > 1.0).any() or (texture < 0.0).any():\n",
    "    print(\"point is out the texture limits\")\n",
    "else:\n",
    "    print(\"point is in the texture limits\")\n",
    "\"\"\"\n",
    "\n",
    "print()\n",
    "# transform point from pitch to texture plane\n",
    "pitch = np.array([x, y])\n",
    "print(\"pitch: {}\".format(pitch))\n",
    "texture = pitch_to_texture(pitch, P)\n",
    "print(\"texture: {}\".format(texture))\n",
    "\n",
    "print()\n",
    "# transform point from texture to pitch\n",
    "print(\"texture: {}\".format(texture))\n",
    "pitch = texture_to_pitch(texture, P)\n",
    "print(\"pitch: {}\".format(pitch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix P for Panorama\n",
    "\n",
    "## How to get Panorama camera parameters: *src_width, src_height, zoom, skew, pan, tilt, roll, Tx, Ty, Tz* \n",
    "You can find camera parameters **`zoom, skew, pan, tilt, roll, Tx, Ty, Tz`** in `C:\\AutomaticTV\\data\\virtual_cameras\\{id}.xml`. In XML `<CameraModel name=\"PANORAMA\">` tag, for instance:\n",
    "\n",
    "```\n",
    "    <CameraModel name=\"PANORAMA\">\n",
    "      <Width>5760</Width>\n",
    "      <Height>1080</Height>\n",
    "      <Zoom>0.45361389</Zoom>\n",
    "      <AspectRatio>5.3333333</AspectRatio>\n",
    "      <Skew>0</Skew>\n",
    "      <Pan>-2.0953152</Pan>\n",
    "      <Tilt>108.76381</Tilt>\n",
    "      <Roll>10</Roll>\n",
    "      <Tx>0.48063888</Tx>\n",
    "      <Ty>-0.30635475</Ty>\n",
    "      <Tz>87.349004</Tz>\n",
    "    </CameraModel>\n",
    "```\n",
    "* **src_width** is `5760`\n",
    "* **src_height** is `1080`\n",
    "\n",
    "**NOTE: Do not use this `AspectRatio`.**\n",
    "\n",
    "## How to get Panorama camera *offset_x* and *offset_y*\n",
    "You can find **`offset_x`** and **`offset_y`** in `C:\\AutomaticTV\\data\\virtual_cameras\\{id}.xml` file tag `<PanoramaOffsetX>` and `<PanoramaOffsetY>`\n",
    "```\n",
    "    <PanoramaOffsetX>0</PanoramaOffsetX>\n",
    "    <PanoramaOffsetY>0</PanoramaOffsetY>\n",
    "```\n",
    "\n",
    "## How to get Panorama camera *src_width* and *src_height*\n",
    "It can be found in `C:\\AutomaticTV\\data\\productions\\{id}.xml`. In XML `<panorama><realization>` tag, for instance:`\n",
    "```\n",
    "    <width>3840</width>\n",
    "    <height>1080</height>\n",
    "```\n",
    "\n",
    "## How to get Panorama camera *aspect_ratio, state_x, state_y, state_zoom*\n",
    "It can be found in `C:\\AutomaticTV\\data\\productions\\{id}.xml`. In XML `<panorama><realization><operators><operator name=\"panorama\"><currentState>` tag, for instance:\n",
    "\n",
    "```\n",
    "          <currentState>\n",
    "            <elem>0.500000</elem>\n",
    "            <elem>0.500000</elem>\n",
    "            <elem>1.000000</elem>\n",
    "            <elem>0.453614</elem>\n",
    "            <elem>3.555556</elem>\n",
    "            <elem>0.000000</elem>\n",
    "            <elem>-2.095315</elem>\n",
    "            <elem>108.763810</elem>\n",
    "            <elem>0.000000</elem>\n",
    "            <elem>0.480639</elem>\n",
    "            <elem>-0.306355</elem>\n",
    "            <elem>87.349004</elem>\n",
    "          </currentState>\n",
    "```\n",
    "where:\n",
    "* ***aspect_ratio*** is the 4th elem `3.555556`\n",
    "* ***state_x*** is the 1st elem `0.500000`\n",
    "* ***state_y*** is the 2nd elem `0.500000`\n",
    "* ***state_zoom*** is the 3rd elem `1.000000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_full_projection_matrix_with_crop(aspect_ratio, zoom, skew, pan, tilt, roll, Tx, Ty, Tz, crop_tx, crop_ty, crop_zoom):\n",
    "    \"\"\"\n",
    "    Creates projection matrix P from camera model parameters\n",
    "    :param aspect_ratio: camera aspect ratio = dst_width / dst_height\n",
    "    :param zoom: camera focal\n",
    "    :param skew:\n",
    "    :param pan:\n",
    "    :param tilt:\n",
    "    :param roll:\n",
    "    :param Tx:\n",
    "    :param Ty:\n",
    "    :param Tz:\n",
    "    :param crop_tx:\n",
    "    :param crop_ty:\n",
    "    :param crop_zoom:\n",
    "    :return: the projection Matrix P\n",
    "    \"\"\"\n",
    "    K = np.array([[crop_zoom * zoom, crop_zoom * skew, 0.5 + crop_tx], \n",
    "                  [0.0, crop_zoom * zoom * aspect_ratio, 0.5 + crop_ty],\n",
    "                  [0.0, 0.0, 1.0]])\n",
    "\n",
    "    # Rotation matrix\n",
    "    Rpan = rodrigues(np.array([0.0, 0.0, pan*math.pi/180.0]))\n",
    "    Rtilt = rodrigues(np.array([tilt*math.pi/180.0, 0.0, 0.0]))\n",
    "    Rroll = rodrigues(np.array([0.0, 0.0, roll*math.pi/180.0]))\n",
    "    Mrot = Rroll * Rtilt * Rpan\n",
    "\n",
    "    # Translation vector\n",
    "    t = np.array([Tx, Ty, Tz])\n",
    "    KR = K * Mrot\n",
    "    Kt = np.dot(K, t)\n",
    "\n",
    "    # Projection Martix P\n",
    "    P = np.zeros((3, 4))\n",
    "    P[:, 0] = KR[:, 0].T\n",
    "    P[:, 1] = KR[:, 1].T\n",
    "    P[:, 2] = KR[:, 2].T\n",
    "    P[:, 3] = Kt\n",
    "    return P\n",
    "\n",
    "def get_crop_params(src_width, src_height, offset_x, offset_y, dst_width, dst_height, state_x, state_y, state_zoom):\n",
    "    \"\"\"\n",
    "    Computes crop parameters taking in account source and destination dimensions\n",
    "    : return crop_tx: \n",
    "    : return crop_ty:\n",
    "    : return crop_zoom:\n",
    "    \"\"\"\n",
    "    width_ratio_inv = float(src_width) / float(dst_width)\n",
    "    height_ratio_inv = float(src_height) / float(dst_height)\n",
    "    crop_tx = (0.5 - state_x + offset_y) * (state_zoom * width_ratio_inv)\n",
    "    crop_ty = (0.5 - state_x + offset_y) * (state_zoom * height_ratio_inv)\n",
    "    crop_zoom = state_zoom * max(width_ratio_inv, height_ratio_inv)\n",
    "    \n",
    "    return crop_tx, crop_ty, crop_zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panorama matrix P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop: 0.0, 0.0, 1.5\n",
      "[[  4.96894228e-01   4.71164433e-01  -1.69901810e-01   3.46031487e+01]\n",
      " [  2.41603659e-04  -1.31142328e-01  -1.83440982e+00   2.93200755e+01]\n",
      " [ -1.73267466e-03   9.40494815e-01  -3.39803620e-01   6.89189280e+01]]\n"
     ]
    }
   ],
   "source": [
    "camera_model = {\n",
    "    \"aspect_ratio\": 3.555556,\n",
    "    \"zoom\": 0.33184094,\n",
    "    \"skew\": 0.0,\n",
    "    \"pan\": -0.10555596,\n",
    "    \"tilt\": 109.86491,\n",
    "    \"roll\": 0.0,\n",
    "    \"Tx\": 0.2886617,\n",
    "    \"Ty\": -2.903907,\n",
    "    \"Tz\": 68.918928}\n",
    "\n",
    "crop_params = {\n",
    "    \"src_width\": 5760,\n",
    "    \"src_height\": 1080,\n",
    "    \"offset_x\": 0.0,\n",
    "    \"offset_y\": 0.0,\n",
    "    \"dst_width\": 3840,\n",
    "    \"dst_height\": 1080,\n",
    "    \"state_x\": 0.5,\n",
    "    \"state_y\": 0.5,\n",
    "    \"state_zoom\": 1.0}\n",
    "\n",
    "\n",
    "# compute crop from params\n",
    "crop_tx, crop_ty, crop_zoom = get_crop_params(**crop_params)\n",
    "print(\"crop: {}, {}, {}\".format(crop_tx, crop_ty, crop_zoom))\n",
    "\n",
    "# compute matrix P\n",
    "P_proj_Pan = camera_full_projection_matrix_with_crop(**camera_model, crop_tx=crop_tx, crop_ty=crop_ty, crop_zoom=crop_zoom)\n",
    "print(P_proj_Pan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Left matrix P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera_model = {\n",
    "    \"aspect_ratio\": 1.7777778,\n",
    "    \"zoom\": 1.2298668,\n",
    "    \"skew\": 0.0,\n",
    "    \"pan\": -35.048991,\n",
    "    \"tilt\": 108.34705,\n",
    "    \"roll\": -11.873014,\n",
    "    \"Tx\": 38.049879,\n",
    "    \"Ty\": -5.1018767,\n",
    "    \"Tz\": 56.809674}\n",
    "P_proj_ML = camera_full_projection_matrix(**camera_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Center matrix P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MC\n",
    "camera_model = {\n",
    "    \"aspect_ratio\": 1.7777778,\n",
    "    \"zoom\": 1.1596733,\n",
    "    \"skew\": 0.0,\n",
    "    \"pan\": 0.3709719,\n",
    "    \"tilt\": 112.66264,\n",
    "    \"roll\": 0.85281113,\n",
    "    \"Tx\": 0.32114744,\n",
    "    \"Ty\": -6.2029192,\n",
    "    \"Tz\": 68.733923}\n",
    "P_proj_MC = camera_full_projection_matrix(**camera_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## example on Master videos only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width_master = 1920\n",
    "height_master = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_master = np.array([[width_master,0,0], [0,height_master,0] ,[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLtex_to_pitch: [ -9.31987664 -33.7921301 ]\n",
      "pitch_to_MCtex: [ 0.22248691  0.86857492]\n",
      "MCpix: [427 938]\n"
     ]
    }
   ],
   "source": [
    "texture = np.array([0.95,0.95])\n",
    "\n",
    "# Texture on Master Left Camer to pitch\n",
    "MLtoPitch= texture_to_pitch(texture,P_proj_ML)\n",
    "print(\"MLtex_to_pitch: {}\".format(MLtoPitch))\n",
    "\n",
    "# Pitch to texture on Master Center Camera\n",
    "PitchtoMC = pitch_to_texture(MLtoPitch, P_proj_MC)\n",
    "print(\"pitch_to_MCtex: {}\".format(PitchtoMC))\n",
    "print(\"MCpix: {}\".format(texture_to_image(PitchtoMC, 1920, 1080)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coord on Master Left:  1824.0 1026.0\n"
     ]
    }
   ],
   "source": [
    "PImageML = im_master*np.append(texture,1)\n",
    "print (\"Coord on Master Left: \", PImageML[0][0], PImageML[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coord on Master Center:  427.174875943 938.060913584\n"
     ]
    }
   ],
   "source": [
    "PImageMC = im_master*np.append(PitchtoMC,1)\n",
    "print  (\"Coord on Master Center: \", PImageMC[0][0], PImageMC[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example on Master to Panorama video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width_master = 1920\n",
    "height_master = 1080\n",
    "im_master = np.array([[width_master,0,0], [0,height_master,0] ,[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width_pan = 3840\n",
    "height_pan = 1080\n",
    "im_pan = np.array([[width_pan,0,0], [0,height_pan,0] ,[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texture = np.array([0.95,0.95])\n",
    "\n",
    "# Texture on Master Left Camer to pitch\n",
    "MLtoPitch= texture_to_pitch(texture,P_proj_ML)\n",
    "\n",
    "# pitch to panorama texture\n",
    "PitchtoPan = pitch_to_texture(MLtoPitch, P_proj_Pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coord on Master Left:  1824.0 1026.0\n"
     ]
    }
   ],
   "source": [
    "PImageML = im_master*np.append(texture,1)\n",
    "print (\"Coord on Master Left: \", PImageML[0][0], PImageML[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coord on Master Left:  1452.18014986 1026.0\n"
     ]
    }
   ],
   "source": [
    "PImagePan = im_pan*np.append(PitchtoPan,1)\n",
    "print (\"Coord on Master Left: \", PImagePan[0][0], PImageML[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ML_tex: [ 0.95  0.95]\n",
      "p_ML_pix: [1824 1026]\n",
      "p_pitch: [ -9.31987664 -33.7921301 ]\n",
      "p_MC_tex: [ 0.22248691  0.86857492]\n",
      "p_MC_pix: [427 938]\n",
      "p_Pan_tex: [ 0.37817191  0.90837128]\n",
      "p_Pan_pix: [1452  981]\n",
      "\n",
      "p_pitch_: [ -9.31987664 -33.7921301 ]\n",
      "[[  4.96894228e-01   4.71164433e-01  -1.69901810e-01   3.46031487e+01]\n",
      " [  2.41603659e-04  -1.31142328e-01  -1.83440982e+00   2.93200755e+01]\n",
      " [ -1.73267466e-03   9.40494815e-01  -3.39803620e-01   6.89189280e+01]]\n"
     ]
    }
   ],
   "source": [
    "# texture point in ML\n",
    "p_ML_tex = np.array([0.95,0.95])\n",
    "print(\"p_ML_tex: {}\".format(p_ML_tex))\n",
    "print(\"p_ML_pix: {}\".format(texture_to_image(p_ML_tex, 1920, 1080)))\n",
    "# Through ML\n",
    "p_pitch = texture_to_pitch(p_ML_tex, P_proj_ML)\n",
    "print(\"p_pitch: {}\".format(p_pitch))\n",
    "\n",
    "# p_pitch to MC\n",
    "p_MC_tex = pitch_to_texture(p_pitch, P_proj_MC)\n",
    "print(\"p_MC_tex: {}\".format(p_MC_tex))\n",
    "print(\"p_MC_pix: {}\".format(texture_to_image(p_MC_tex, 1920, 1080)))\n",
    "\n",
    "# p_pitch to Panorama\n",
    "p_Pan_tex = pitch_to_texture(p_pitch, P_proj_Pan)\n",
    "print(\"p_Pan_tex: {}\".format(p_Pan_tex))\n",
    "print(\"p_Pan_pix: {}\".format(texture_to_image(p_Pan_tex, 3840, 1080)))\n",
    "\n",
    "print()\n",
    "# Panorama to pitch\n",
    "p_pitch_ = texture_to_pitch(p_Pan_tex, P_proj_Pan)\n",
    "print(\"p_pitch_: {}\".format(p_pitch_))\n",
    "\n",
    "print(P_proj_Pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
